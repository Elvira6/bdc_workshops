{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop #1 - Simple Data Transformations\n",
    "\n",
    "Welcome to the workshops! Every week we'll cover a new datascience topic in Python to help familiarize your team for the competition! Every workshop will teach you the bare essentials of data science. There is no fluff. Please complete every workshop to give yourself a full grasp of the concept. If you have any trouble with the workshops please message the #workshops channel on Slack. Slack is a place for everybody to learn so if you know how to answer something feel free to respond to that channel!\n",
    "\n",
    "This week will cover dataframe manipulation and we'll be working with the Toronto *Rain Gauge Locations and Precipitation* dataset.\n",
    "\n",
    "This is large collection of rainfall measurements taken over the past 3 years. (Link to the complete dataset: https://goo.gl/gBYrb4). I have already downloaded the data for you and it is archived within the *2017_rainfall_data* folder. For the sake of simplicity, we'll just be looking at data from 2017.\n",
    "\n",
    "## A few ground rules\n",
    "\n",
    " - Remember to run every cell\n",
    "     - Parts of this workshop won't work if this condition isn't met\n",
    " - Please don't change my asserts\n",
    "     - If you're receiving an incorrect answer please don't change the assert answer just to get it right. You            won't learn anything and will probably fail the rest of the tutorial. Feel free to message slack on the #workshops channel if you get stuck.\n",
    "     \n",
    "Lets begin by importing some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#don't mind this. I'm just trying to double check you work :)\n",
    "def assertAns(condition, fail_str, suc_str):\n",
    "    assert condition, fail_str\n",
    "    print(suc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #Linear algebra\n",
    "import requests as req #Python's http library\n",
    "import re #Python's Regex library\n",
    "import pandas as pd #Python's data manipulation library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost everything you do in computer science requires a datastructure to store information. Since data science requires a lot of space to store this information really smart academics have invented the dataframe to hold vast amounts of data.\n",
    "\n",
    "Dataframes are basically tables. Each dataframe is comprised of colummns, rows, and a header.\n",
    "\n",
    "Yep sounds like a table. The reason why a dataframe resembles a table is because tables are very structured and easy to understand. If you look at a table, all cells underneath a header are part of the same \"attribute\". This standardization allows tables to store information in a neat manner.\n",
    "\n",
    "Lets go ahead and make our first dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruits</th>\n",
       "      <th>vegitables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banana</td>\n",
       "      <td>onion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fruits vegitables\n",
       "0   apple     potato\n",
       "1  banana      onion"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run this cell to make your first dataframe!\n",
    "\n",
    "a2DArray = [[\"apple\",\"potato\"],\n",
    "            [\"banana\",\"onion\"]]\n",
    "\n",
    "\n",
    "myFirstDataframe = pd.DataFrame(a2DArray,columns=[\"fruits\",\"vegitables\"])\n",
    "#the following variable is the last variable that is returned in the cell\n",
    "myFirstDataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note:\n",
    " - The *columns* attribute in the *pd.DataFrame()* command specifies the headers for the dataframe\n",
    " - The numbers on the left hand side of the dataframe are the row indexes. Note how they were automatically generated.\n",
    " - Jupyter automatically displays the dataframe if the dataframe LAST VARIABLE to be RETURNED in the cell\n",
    " - We pass in a 2D array to make the dataframe because tables (and subsiquently dataframes) are basically 2D arrays!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a better understanding of the structure of a dataframe, lets import our dataset into a dataframe!\n",
    "\n",
    "Since CSV files are meant to be read by excel (which converts data into a table), it is easy for a dataframe to represent data originating from a CSV file.\n",
    "\n",
    "In fact, transforming data from a CSV file into a dataframe is so easy there is a built in function in Pandas that can turn a CSV file into a dataframe in one step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note how I am navigating through our file system to find the csv file I want.\n",
    "#the directory you start in is always in relation to the directory of the current notebook\n",
    "rainfallDF = pd.read_csv(\"../2017_rainfall_data/rainfall201706.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets don't always come in CSV files! If you find a dataset that came as a JSON file or even a a shapefile, don't hesitate to ask how to import these files on Slack!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the first five rows of our dataframe using the _head(n)_ command. By default _n=5_ so if you use _dataframe.head()_, it will return the first 5 elements of our dataframe. You'll mainly be using this command to have a glance at your data. It's pretty useful.\n",
    "\n",
    "Try that with our *rainfallDF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>rainfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:05:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:10:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:15:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:20:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    name                 date  rainfall\n",
       "0  7677  RG_001  2017-06-01T00:00:00       0.0\n",
       "1  7677  RG_001  2017-06-01T00:05:00       0.0\n",
       "2  7677  RG_001  2017-06-01T00:10:00       0.0\n",
       "3  7677  RG_001  2017-06-01T00:15:00       0.0\n",
       "4  7677  RG_001  2017-06-01T00:20:00       0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainfallDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Sometimes we want to select a certain index (row) of a dataframe. To do so, we simply put _iloc[n]_ before our dataframe:\n",
    "\n",
    "_dataframe_.iloc[n]\n",
    "\n",
    "Much like arrays, we replace _n_ with the index that we want to retrieve.\n",
    "\n",
    "Try to grab the first row of our dataframe using the *iloc[]* command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-0b356c69db5f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-0b356c69db5f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    rainfallRow.<FILL IN>\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "rainfallRow.<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets select a certain column within our dataframe!\n",
    "we do so like this:\n",
    "\n",
    "newVarToHoldColumnVals = DF[\"theHeaderForTheColumn\"]\n",
    "\n",
    "Try to make a variable to hold all the dates of our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-1307c7826dc2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-1307c7826dc2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    datesColumn = <FILL IN>\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "datesColumn = <FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The Data Science Process\n",
    "\n",
    "Whenever we're working with a dataset we usually go through 4 stages:\n",
    "\n",
    "1. Data Inspection\n",
    "2. Normalization and cleaning\n",
    "3. Gathering insights (Feature Engineering)\n",
    "4. Generate the models\n",
    "5. Storytelling\n",
    "\n",
    "### Data Inspection\n",
    "Every good data science project begins with data inspection. When we inspect the data we want to look at the beast and see what's coming. The point of inspecting the data is to gather context on what we're looking at so we can begin to ask ourselves questions to answer!\n",
    "\n",
    "Some things I usually look at when I'm glancing at data are the means of the columns, the unique values of categorical variables, counts, max, mins, and modes. This should spark some questions if you see an abnormally high number in a column.\n",
    "\n",
    "### Normalization and Cleaning\n",
    "Once we understand our data, we'll have to start cleaning our data for modeling. This involves clearing rows with null values (or imputing them with averages), removing useless columns (or columns that are too similiar to others), placing all values into a linear scale, or converting all numbers to a universal unit for your dataset.\n",
    "\n",
    "\n",
    "### Gathering Insights\n",
    "\n",
    "Before I discuss about insight gathering you need to know these terms:\n",
    "\n",
    "__Data__ are values that describes something. Data is usually gathered from sensors or events that happen on your phone/computer (like a tap)\n",
    "\n",
    "__Information__ is data that is useful. Data is not meaningful. Information is.\n",
    "\n",
    "__Attributes__ are the variables of your dataset. If you have a dataset that describes a windows, the attributes of the dataset are the dimensions of the window, the types of material that it is made from. Think of attributes as the headers of your dataset. In a dataframe, the values that describes the attributes are the data underneath the headers.\n",
    "\n",
    "__Features__ are attributes that are useful. Attributes are not meaningful. Features are. The moment that an attribute tells us something about the dataset is the moment that it becomes a feature. Features are the useful bits of information that are fed into machine learning algorithms. Attributes can't be fed into machine learning algorithms because they don't tell the algorithm anything. It's just a jumble of numbers.\n",
    "\n",
    "__Feature Engineering__ is the extraction of meaningful information out of attributes in our dataset. Think of it as turning attributes into features. An example of feature engineering is determining the day of the week given a date. We are creating a new feature (the day of the week) given an attribute (the date). Another example is extracting the surname out of a full name. This is considered feature engineering because surnames can identify people who are part of the same family in a dataset.\n",
    "\n",
    "With our data cleaned and normalized we feature engineer to discover more patterns and insights within our dataset. The goal of feature engineering is to provide more variables for our algorithms to play with. By manually identifying these patterns, the computer doesn't have to expend additional effort to discover these patterns algorithmically.\n",
    "\n",
    "This is the hardest part of data science so don't worry if you need more explination or aren't good at it. Feel free to message @curtischong5 on Slack if you want further explination!\n",
    "\n",
    "\n",
    "\n",
    "From experience, steps 1-3 should take up 90% of your time. It also just so happens that the first three steps occur organically with the inception of your questions. Once you start looking at the data, you'll want to answer some questions... which will lead you to clean the data to gather insights from it. Then you may have more questions so you'll repeat the cycle.\n",
    "\n",
    "### Generating the models\n",
    "Once our dataset has been prepared (and you've answered most of your questions), we can finally have some fun and do some machine learning to make predictions! Depending on the type of dataset, you may want to implement a regression algorithm to predict a numeric value (like predicting the speed of a car given these variables) or sort variables into different categories (like passing or failing a test). We'll dive deeper into machine learning in workshop #3.\n",
    "\n",
    "### Storytelling\n",
    "The purpose of data science is to tell a story. We crunch numbers to discover new things and to propose new policies. Our world will crumble if decisions were not backed by data. So whatever you do when you're analyzing your dataset(s) always keep this purpose in the back of your mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets inspect *our* data. One useful method to learn about the specifics of your dataset is by running the *describe()* function on our *rainfallDF*. So lets try that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rainfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>359051.000000</td>\n",
       "      <td>347427.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7715.657639</td>\n",
       "      <td>0.012369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>81.252303</td>\n",
       "      <td>0.145904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7674.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7684.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7696.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7708.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8049.000000</td>\n",
       "      <td>9.140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       rainfall\n",
       "count  359051.000000  347427.000000\n",
       "mean     7715.657639       0.012369\n",
       "std        81.252303       0.145904\n",
       "min      7674.000000       0.000000\n",
       "25%      7684.000000       0.000000\n",
       "50%      7696.000000       0.000000\n",
       "75%      7708.000000       0.000000\n",
       "max      8049.000000       9.140000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainfallDF.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note: std means standard deviation and the numbers at the 25%, 50%, and 75% mark are numeric percentiles of that column. (Since I'm bad at explaining this check out this link:) https://stackoverflow.com/questions/39567712/python-pandas-how-is-25-percentile-calculated-by-describe-function\n",
    "\n",
    "That interesting. Notice how the number of rainfall \"data\" doesn't match the number of *ID*s. This doesn't make sense as every id must have a corresponding *rainfall* value. I suspect that some missing data is in the rainfall column. Lets run the *dropna()* function to try to remove all rows that are missing data or contains \"NaN\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-33f8f896b974>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-33f8f896b974>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    droppedNa = rainfallDF.<FILL IN>\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "droppedNa = rainfallDF.<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets re-run the *describe()* function on our dataframe to see if the number of *ID*s and *rainfall* are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rainfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>347427.000000</td>\n",
       "      <td>347427.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7716.586077</td>\n",
       "      <td>0.012369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>82.415253</td>\n",
       "      <td>0.145904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7674.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7685.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7697.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7709.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8049.000000</td>\n",
       "      <td>9.140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id       rainfall\n",
       "count  347427.000000  347427.000000\n",
       "mean     7716.586077       0.012369\n",
       "std        82.415253       0.145904\n",
       "min      7674.000000       0.000000\n",
       "25%      7685.000000       0.000000\n",
       "50%      7697.000000       0.000000\n",
       "75%      7709.000000       0.000000\n",
       "max      8049.000000       9.140000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "droppedNa.<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm a bit curious... What is the average amount of rainfall that usually falls? Assign that number into the *averageRainfall* variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-f9ab99d46445>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-f9ab99d46445>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    averageRainfall = <FILL IN>\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "averageRainfall = <FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "assertAns(averageRainfall == 0.012369, \"That is not the average rainfall!\",\"Test passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A bit more about the methodology we just went through. Notice how we asked ourselves some questions after inspecting the data. Next, we had to clean our dataset to answer our question. Finally, we asked ourselves more questions about the data. We kept jumping back and forth on the four stages! Since a large part of data science falls within the realm of data exploration, it is hard to estimate how long it'll take to analyze data. So start early on your projects and give yourself a deadline!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets practice selecting columns again. Try to select the *rainfall* column below and save it into the dataframe *rainfallColumn* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rainfallColumn = rainfallDF[<FILL IN>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using this column, lets try to run the *mean()* function on it. This will give us the average amount of rainfall that fell. We're going to save this value into the *avgRainfall* variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avgRainfall = rainfallColumn.<FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(avgRainfall == 0.012369, \"That is not the average rainfall!\", \"Test Passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also run the *sum()* function on the *rainfallColumn* to determine how much rain had fell on Toronto in the first few months of 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgRainfall = rainfallColumn.<FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4297.2639990000007"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertAns(avgRainfall == 4297.2639990000007, \"That is not the total rainfall!\",\"Test passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how *averageRainFall* is the same value as the value we were told from the *describe()* function.\n",
    "\n",
    "I'm going to showcase one last function: *unique()*. This function will display all unique values in a column which makes it really useful for categorical columns. More information about categorical variables here: http://www.stat.yale.edu/Courses/1997-98/101/catdat.htm.\n",
    "\n",
    "Lets run *unique()* on the \"name\" column of the *rainfallDF*. We'll save this value to the *uniqueNames* variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uniqueNames = rainfallDF[<FILL IN>].<FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed\n"
     ]
    }
   ],
   "source": [
    "assertAns(list(uniqueNames) == ['RG_001', 'RG_002', 'RG_003', 'RG_004', 'RG_006', 'RG_007','RG_012', 'RG_013', 'RG_014', 'RG_015', 'RG_016', 'RG_017','RG_018', 'RG_019', 'RG_020', 'RG_021', 'RG_022', 'RG_023','RG_024', 'RG_025', 'RG_027', 'RG_028', 'RG_030', 'RG_031','RG_033', 'RG_034', 'RG_035', 'RG_036', 'RG_037', 'RG_038','RG_040', 'RG_041', 'RG_042', 'RG_044', 'RG_045', 'RG_046','RG_047', 'RG_048', 'RG_049', 'RG_051', 'RG_052', 'RG_054','RG_055', 'RG_056'], \"Those aren't the unique station names!\",\"Test passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These small functions (*sum()*, *mean()*, *unique()*), and others like it (*mode()*, *median()*, etc.) are great for glancing at your dataset. They allow you to take a look and learn how data varies for individual columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we end this workshop, I would like to draw attention to one of the more important aspects of data analytics... learning how to generate features from existing attributes. In other words, I'll give you the tool to assist you with the third stage. This time, I'll lead by example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2017-06-01T00:00:00', '2017-06-01T00:05:00', '2017-06-01T00:10:00',\n",
       "       ..., '2017-06-29T23:50:00', '2017-06-29T23:55:00',\n",
       "       '2017-06-30T00:00:00'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rainfallDF[\"date\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:05:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:10:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:10:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:15:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:20:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:20:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    name                 date  rainfall      time\n",
       "0  7677  RG_001  2017-06-01T00:00:00       0.0  00:00:00\n",
       "1  7677  RG_001  2017-06-01T00:05:00       0.0  00:05:00\n",
       "2  7677  RG_001  2017-06-01T00:10:00       0.0  00:10:00\n",
       "3  7677  RG_001  2017-06-01T00:15:00       0.0  00:15:00\n",
       "4  7677  RG_001  2017-06-01T00:20:00       0.0  00:20:00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#I'm a curious and want to know what is the average rainfall for every hour of the day\n",
    "#I'll begin by looping through each row in the dataframe and take the \"time\" within the\n",
    "#date attribute and put it into another column called time\n",
    "transformedDF = rainfallDF #lets make a copy of the existing dataframe\n",
    "for index, row in transformedDF.iterrows():\n",
    "    dateForThisRow = row[\"date\"]\n",
    "    theTime = dateForThisRow.split(\"T\")[1] #values in the date column looks like this: 2017-06-01T00:00:00\n",
    "    #I am spliting the string on the \"T\" and selecting the \"1\" index because\n",
    "    #that was the time when the value was taken\n",
    "    rainfallDF.set_value(index,'time', theTime) #use this command to set the values of a new column\n",
    "#lets have a quick look at the transformed dataframe:\n",
    "transformedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00:00:00', '00:05:00', '00:10:00', '00:15:00', '00:20:00',\n",
       "       '00:25:00', '00:30:00', '00:35:00', '00:40:00', '00:45:00',\n",
       "       '00:50:00', '00:55:00', '01:00:00', '01:05:00', '01:10:00',\n",
       "       '01:15:00', '01:20:00', '01:25:00', '01:30:00', '01:35:00',\n",
       "       '01:40:00', '01:45:00', '01:50:00', '01:55:00', '02:00:00',\n",
       "       '02:05:00', '02:10:00', '02:15:00', '02:20:00', '02:25:00',\n",
       "       '02:30:00', '02:35:00', '02:40:00', '02:45:00', '02:50:00',\n",
       "       '02:55:00', '03:00:00', '03:05:00', '03:10:00', '03:15:00',\n",
       "       '03:20:00', '03:25:00', '03:30:00', '03:35:00', '03:40:00',\n",
       "       '03:45:00', '03:50:00', '03:55:00', '04:00:00', '04:05:00',\n",
       "       '04:10:00', '04:15:00', '04:20:00', '04:25:00', '04:30:00',\n",
       "       '04:35:00', '04:40:00', '04:45:00', '04:50:00', '04:55:00',\n",
       "       '05:00:00', '05:05:00', '05:10:00', '05:15:00', '05:20:00',\n",
       "       '05:25:00', '05:30:00', '05:35:00', '05:40:00', '05:45:00',\n",
       "       '05:50:00', '05:55:00', '06:00:00', '06:05:00', '06:10:00',\n",
       "       '06:15:00', '06:20:00', '06:25:00', '06:30:00', '06:35:00',\n",
       "       '06:40:00', '06:45:00', '06:50:00', '06:55:00', '07:00:00',\n",
       "       '07:05:00', '07:10:00', '07:15:00', '07:20:00', '07:25:00',\n",
       "       '07:30:00', '07:35:00', '07:40:00', '07:45:00', '07:50:00',\n",
       "       '07:55:00', '08:00:00', '08:05:00', '08:10:00', '08:15:00',\n",
       "       '08:20:00', '08:25:00', '08:30:00', '08:35:00', '08:40:00',\n",
       "       '08:45:00', '08:50:00', '08:55:00', '09:00:00', '09:05:00',\n",
       "       '09:10:00', '09:15:00', '09:20:00', '09:25:00', '09:30:00',\n",
       "       '09:35:00', '09:40:00', '09:45:00', '09:50:00', '09:55:00',\n",
       "       '10:00:00', '10:05:00', '10:10:00', '10:15:00', '10:20:00',\n",
       "       '10:25:00', '10:30:00', '10:35:00', '10:40:00', '10:45:00',\n",
       "       '10:50:00', '10:55:00', '11:00:00', '11:05:00', '11:10:00',\n",
       "       '11:15:00', '11:20:00', '11:25:00', '11:30:00', '11:35:00',\n",
       "       '11:40:00', '11:45:00', '11:50:00', '11:55:00', '12:00:00',\n",
       "       '12:05:00', '12:10:00', '12:15:00', '12:20:00', '12:25:00',\n",
       "       '12:30:00', '12:35:00', '12:40:00', '12:45:00', '12:50:00',\n",
       "       '12:55:00', '13:00:00', '13:05:00', '13:10:00', '13:15:00',\n",
       "       '13:20:00', '13:25:00', '13:30:00', '13:35:00', '13:40:00',\n",
       "       '13:45:00', '13:50:00', '13:55:00', '14:00:00', '14:05:00',\n",
       "       '14:10:00', '14:15:00', '14:20:00', '14:25:00', '14:30:00',\n",
       "       '14:35:00', '14:40:00', '14:45:00', '14:50:00', '14:55:00',\n",
       "       '15:00:00', '15:05:00', '15:10:00', '15:15:00', '15:20:00',\n",
       "       '15:25:00', '15:30:00', '15:35:00', '15:40:00', '15:45:00',\n",
       "       '15:50:00', '15:55:00', '16:00:00', '16:05:00', '16:10:00',\n",
       "       '16:15:00', '16:20:00', '16:25:00', '16:30:00', '16:35:00',\n",
       "       '16:40:00', '16:45:00', '16:50:00', '16:55:00', '17:00:00',\n",
       "       '17:05:00', '17:10:00', '17:15:00', '17:20:00', '17:25:00',\n",
       "       '17:30:00', '17:35:00', '17:40:00', '17:45:00', '17:50:00',\n",
       "       '17:55:00', '18:00:00', '18:05:00', '18:10:00', '18:15:00',\n",
       "       '18:20:00', '18:25:00', '18:30:00', '18:35:00', '18:40:00',\n",
       "       '18:45:00', '18:50:00', '18:55:00', '19:00:00', '19:05:00',\n",
       "       '19:10:00', '19:15:00', '19:20:00', '19:25:00', '19:30:00',\n",
       "       '19:35:00', '19:40:00', '19:45:00', '19:50:00', '19:55:00',\n",
       "       '20:00:00', '20:05:00', '20:10:00', '20:15:00', '20:20:00',\n",
       "       '20:25:00', '20:30:00', '20:35:00', '20:40:00', '20:45:00',\n",
       "       '20:50:00', '20:55:00', '21:00:00', '21:05:00', '21:10:00',\n",
       "       '21:15:00', '21:20:00', '21:25:00', '21:30:00', '21:35:00',\n",
       "       '21:40:00', '21:45:00', '21:50:00', '21:55:00', '22:00:00',\n",
       "       '22:05:00', '22:10:00', '22:15:00', '22:20:00', '22:25:00',\n",
       "       '22:30:00', '22:35:00', '22:40:00', '22:45:00', '22:50:00',\n",
       "       '22:55:00', '23:00:00', '23:05:00', '23:10:00', '23:15:00',\n",
       "       '23:20:00', '23:25:00', '23:30:00', '23:35:00', '23:40:00',\n",
       "       '23:45:00', '23:50:00', '23:55:00'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformedDF[\"time\"].unique() #wow. it seems like they take measurements every 5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>time</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-02T00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-03T00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-04T00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-05T00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    name                 date  rainfall      time hour\n",
       "0     7677  RG_001  2017-06-01T00:00:00       0.0  00:00:00   00\n",
       "288   7677  RG_001  2017-06-02T00:00:00       0.0  00:00:00   00\n",
       "576   7677  RG_001  2017-06-03T00:00:00       0.0  00:00:00   00\n",
       "864   7677  RG_001  2017-06-04T00:00:00       0.0  00:00:00   00\n",
       "1152  7677  RG_001  2017-06-05T00:00:00       0.0  00:00:00   00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with this new dataframe I want to create an array that describes the average amount of rainfall for every hour.\n",
    "#I'll start off by selecting just the first minute of the first hour of the day\n",
    "firstMinuteDF = transformedDF[transformedDF[\"time\"] == \"00:00:00\"]\n",
    "firstMinuteDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>time</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:05:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:05:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:10:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:10:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:15:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:20:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:20:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id    name                 date  rainfall      time hour\n",
       "0  7677  RG_001  2017-06-01T00:00:00       0.0  00:00:00   00\n",
       "1  7677  RG_001  2017-06-01T00:05:00       0.0  00:05:00   00\n",
       "2  7677  RG_001  2017-06-01T00:10:00       0.0  00:10:00   00\n",
       "3  7677  RG_001  2017-06-01T00:15:00       0.0  00:15:00   00\n",
       "4  7677  RG_001  2017-06-01T00:20:00       0.0  00:20:00   00"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets manipulate the DF again and add a new \"hour\" column\n",
    "transformedDF2 = transformedDF #lets make a copy of the existing dataframe\n",
    "#we can achieve this by looping through every row of our dataframe and extracting\n",
    "#the \"hour\" value from the date attribute\n",
    "for index, row in transformedDF2.iterrows():\n",
    "    timeForThisRow = row[\"time\"]\n",
    "    theHour = timeForThisRow.split(\":\")[0] #values in the \"time\" column looks like this: 00:00:00\n",
    "    #I am spliting the string on the \":\" and selecting the \"0\" index because that\n",
    "    #is the hour when the value was taken\n",
    "    rainfallDF.set_value(index,'hour', theHour) #use this command to set the values of a new column\n",
    "#lets have a quick look at the transformed dataframe:\n",
    "transformedDF2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm also going to teach you some new selecting commands. Watch how I am selecting all rows that were measured from the first hour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0117780842701\n"
     ]
    }
   ],
   "source": [
    "firstHourDF = transformedDF2[transformedDF2[\"hour\"] == \"00\"] #I'm saying: select all rows\n",
    "#that has an \"hour\" value of \"00\"\n",
    "print(firstHourDF[\"rainfall\"].mean())\n",
    "#the following value is the average amount of rainfall for all measurements\n",
    "#that were taken in the first hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour 00: 0.0117780842701\n",
      "hour 01: 0.0149699861687\n",
      "hour 02: 0.0421227027774\n",
      "hour 03: 0.0203372478585\n",
      "hour 04: 0.00289961336647\n",
      "hour 05: 0.00738124827396\n",
      "hour 06: 0.0254926815797\n",
      "hour 07: 0.0270355785838\n",
      "hour 08: 0.00957183332182\n",
      "hour 09: 0.00285955328124\n",
      "hour 10: 0.00885984665331\n",
      "hour 11: 0.00914015334669\n",
      "hour 12: 0.00492495854063\n",
      "hour 13: 0.0194678176105\n",
      "hour 14: 0.0415913889464\n",
      "hour 15: 0.00759516908213\n",
      "hour 16: 0.0015831433506\n",
      "hour 17: 0.00109329466197\n",
      "hour 18: 0.00149875553097\n",
      "hour 19: 0.00667431890472\n",
      "hour 20: 0.0136510261903\n",
      "hour 21: 0.0059092039801\n",
      "hour 22: 0.00209551454834\n"
     ]
    }
   ],
   "source": [
    "#now lets try the same measurement for all hours of the day\n",
    "arrToHoldHours = []\n",
    "for hour in range(23):\n",
    "    strHour = str(hour)\n",
    "    #here I am formating the \"hour\" so it matches with the style of the hour values in the DF\n",
    "    if len(strHour) == 1:\n",
    "        strHour = \"0\" + strHour\n",
    "    #lets actually do the selecting now\n",
    "    selectedHour = transformedDF2[transformedDF2[\"hour\"] == strHour]\n",
    "    avgRainfallForThatHour = selectedHour[\"rainfall\"].mean() #calculating the mean\n",
    "    arrToHoldHours.append(\"hour \" + strHour + \": \" + str(avgRainfallForThatHour))\n",
    "    \n",
    "#andddd here we are printing the data\n",
    "for oneHour in arrToHoldHours:\n",
    "    print(oneHour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most percipitation happens at 2AM. It might be interesting to see how measurements from different seasons differ and even from different years. (If you're interested download the other datasets https://goo.gl/gBYrb4 and merge them into one big dataframe!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now before I let out the workshop, I'll teach you one last selection method; how to impose multiple rules when selecting rows. You may have noticed how I used *transformedDF[transformedDF[\"time\"] == \"00:00:00\"]* to select all measurements that were taken from the first minute of the day. But what if I want to select values that came from the first minute AND from a specific station... say from *RG_001*. I'll have to use syntax to define multi-condition selection. Here's how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount selected: 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>rainfall</th>\n",
       "      <th>time</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-01T00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-02T00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-03T00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-04T00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>7677</td>\n",
       "      <td>RG_001</td>\n",
       "      <td>2017-06-05T00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    name                 date  rainfall      time hour\n",
       "0     7677  RG_001  2017-06-01T00:00:00       0.0  00:00:00   00\n",
       "288   7677  RG_001  2017-06-02T00:00:00       0.0  00:00:00   00\n",
       "576   7677  RG_001  2017-06-03T00:00:00       0.0  00:00:00   00\n",
       "864   7677  RG_001  2017-06-04T00:00:00       0.0  00:00:00   00\n",
       "1152  7677  RG_001  2017-06-05T00:00:00       0.0  00:00:00   00"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstMinOfDayAndRG_001 = transformedDF[(transformedDF[\"time\"] == \"00:00:00\") & (transformedDF[\"name\"] == \"RG_001\")]\n",
    "#notice the parenthesis between each condition\n",
    "print(\"Amount selected: \" + str(len(firstMinOfDayAndRG_001)))\n",
    "firstMinOfDayAndRG_001.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want to save our work by saving the dataframe we made. (So we don't have to process everything all over again everytime we close Jupyter). The _pickle_ file type can store Python dataframes as a _.pkl_ file. To save our dataframe, run this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedDF.to_pickle(\"../saved_dataframes/workshop1RainfallDF\")\n",
    "#note we're save our pickle file into the saved_dataframes folder\n",
    "#Keeping all your data in one place will keep you organised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Congrats for making it this far. I hope this tutorial was helpful and please don't hesitate to ask for help. Feedback that you provide will be taken into consideration for future workshops and I hope that you learned something. Good luck on your projects!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
